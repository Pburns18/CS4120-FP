{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rohiljaveri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rohiljaveri/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rohiljaveri/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import contractions\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                                               text  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A  My wife took me here on my birthday for breakf...   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA  I have no idea why some people give bad review...   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ  love the gyro plate. Rice is so good and I als...   \n",
       "3  G-WvGaISbqqaMHlNnByodA  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...   \n",
       "4  1uJFq2r5QfJG_6ExMRCaGw  General Manager Scott Petello is a good egg!!!...   \n",
       "\n",
       "  stars  \n",
       "0     5  \n",
       "1     5  \n",
       "2     4  \n",
       "3     5  \n",
       "4     5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in dataset\n",
    "yelp_df = pd.read_csv(\"yelp.csv\")\n",
    "yelp_df = yelp_df[['review_id', 'text', 'stars']]\n",
    "yelp_df['stars'] = yelp_df['stars'].apply(str)\n",
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in dataset\n",
    "movie_df = pd.read_csv(\"movie.csv\")\n",
    "movie_df.head()\n",
    "movie_df = movie_df[['text', 'label']]\n",
    "# yelp_df['stars'] = yelp_df['stars'].apply(str)\n",
    "movie_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_space_tokenization(text):\n",
    "    new_text = text.split(' ')\n",
    "    return new_text\n",
    "\n",
    "def apply_lowercase(text):\n",
    "    new_text = text.lower()\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>first visit...had lunch here today - used my g...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>should be called house of deliciousness!\\n\\ni ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>i recently visited olive and ivy for business ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>my nephew just moved to scottsdale recently so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. i think...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id  \\\n",
       "0     fWKvX83p0-ka4JS3dc6E5A   \n",
       "1     IjZ33sJrzXqU-0X6U8NwyA   \n",
       "2     IESLBzqUCLdSzSqm0eCSxQ   \n",
       "3     G-WvGaISbqqaMHlNnByodA   \n",
       "4     1uJFq2r5QfJG_6ExMRCaGw   \n",
       "...                      ...   \n",
       "9995  Ubyfp2RSDYW0g7Mbr8N3iA   \n",
       "9996  2XyIOQKbVFb6uXQdJ0RzlQ   \n",
       "9997  jyznYkIbpqVmlsZxSDSypA   \n",
       "9998  5UKq9WQE1qQbJ0DJbc-B6Q   \n",
       "9999  vWSmOhg2ID1MNZHaWapGbA   \n",
       "\n",
       "                                                   text stars  \n",
       "0     my wife took me here on my birthday for breakf...     5  \n",
       "1     i have no idea why some people give bad review...     5  \n",
       "2     love the gyro plate. rice is so good and i als...     4  \n",
       "3     rosie, dakota, and i love chaparral dog park!!...     5  \n",
       "4     general manager scott petello is a good egg!!!...     5  \n",
       "...                                                 ...   ...  \n",
       "9995  first visit...had lunch here today - used my g...     3  \n",
       "9996  should be called house of deliciousness!\\n\\ni ...     4  \n",
       "9997  i recently visited olive and ivy for business ...     4  \n",
       "9998  my nephew just moved to scottsdale recently so...     2  \n",
       "9999  4-5 locations.. all 4.5 star average.. i think...     5  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df['text'] = yelp_df['text'].apply(apply_lowercase)\n",
    "#yelp_df['text'] = yelp_df['text'].apply(apply_space_tokenization)\n",
    "yelp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i grew up (b. 1965) watching and loving the th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i put this movie in my dvd player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though i have great interest in biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im a die hard dads army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"western union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>this movie is an incredible piece of work. it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>my wife and i watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>when i first watched flatliners, i was amazed....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      i grew up (b. 1965) watching and loving the th...      0\n",
       "1      when i put this movie in my dvd player, and sa...      0\n",
       "2      why do people who do not know what a particula...      0\n",
       "3      even though i have great interest in biblical ...      0\n",
       "4      im a die hard dads army fan and nothing will e...      1\n",
       "...                                                  ...    ...\n",
       "39995  \"western union\" is something of a forgotten cl...      1\n",
       "39996  this movie is an incredible piece of work. it ...      1\n",
       "39997  my wife and i watched this movie because we pl...      0\n",
       "39998  when i first watched flatliners, i was amazed....      1\n",
       "39999  why would this film be so good, but only gross...      1\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df['text'] = movie_df['text'].apply(apply_lowercase)\n",
    "#yelp_df['text'] = yelp_df['text'].apply(apply_space_tokenization)\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Expirements\n",
    "#### Potentially we do some constants throughout our experiments? I.e Tokenize just by spaces, and lowecase all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lem(text):\n",
    "    lem = WordNetLemmatizer()\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        new_word = lem.lemmatize(word)\n",
    "        new_text.append(new_word)\n",
    "    review = ' '.join(new_text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        new_word = ps.stem(word)\n",
    "        new_text.append(new_word)\n",
    "    review = ' '.join(new_text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraction expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contraction_expansion(text):\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        new_word = contractions.fix(text)\n",
    "        new_text.append(new_word)\n",
    "    review = ' '.join(new_text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Number related text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_number_removal(text):\n",
    "    review = re.sub(r'[0-9]', '', text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_punctuation_removal(text):\n",
    "    review = re.sub(r'[.,!?-_;:&#$@%=+]', '', text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stopword_removal(text):\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        if text in STOP_WORDS:\n",
    "            continue\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    review = ' '.join(new_text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Check Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_spelling_correction(text):\n",
    "    textBlb = TextBlob(text)\n",
    "    textCorrected = textBlb.correct() \n",
    "    return textCorrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER AND POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_spacy(text):\n",
    "    applied_text = NER(text)\n",
    "    return applied_text\n",
    "\n",
    "\n",
    "def get_pos(spacy_text):\n",
    "    print(spacy_text)\n",
    "    new_sentence = []\n",
    "    excluded_tags = {\"NOUN\", \"PRON\", \"PROPN\", \"DET\", \"ADP\", \"PUNCT\",}\n",
    "    for word in spacy_text:\n",
    "        if word.pos_ not in excluded_tags:\n",
    "            new_sentence.append(word.text)\n",
    "    review = ' '.join(new_sentence)\n",
    "    return review\n",
    "\n",
    "# def get_ner(spacy_text):\n",
    "#     for word in spacy_text:\n",
    "        \n",
    "#         print(word.text, word.label_)\n",
    "        \n",
    "# to return the labels\n",
    "# spacy_words = apply_spacy(\"I honestly hated the play, it was so boring\")   \n",
    "# get_pos(spacy_words)\n",
    "\n",
    "# for word in spacy_words.ents:\n",
    "#     print(word.text,word.label_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Certain P.O.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Combination\n",
    "#### Perhaps we run experiments with random combinations of all methods and see best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation & Test Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(gold_labels, predicted_labels, name, clf):\n",
    "    # Reporting metrics & confusion matrix\n",
    "    acc = round(accuracy_score(gold_labels, predicted_labels), 4)\n",
    "    err = round(1 - acc, 4)\n",
    "    pre = round(precision_score(gold_labels, predicted_labels, average='macro'), 4)\n",
    "    rec = round(recall_score(gold_labels, predicted_labels, average='macro'), 4)\n",
    "    f1 = round(f1_score(gold_labels, predicted_labels, average='macro'), 4)\n",
    "\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Error: \", err)\n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"F1-Score: \", f1)\n",
    "\n",
    "    cf_matrix = confusion_matrix(gold_labels, predicted_labels, labels=clf.classes_)\n",
    "    rcParams['figure.figsize'] = 16,12\n",
    "    sns.heatmap(cf_matrix, annot=True, cmap=\"Greens\", xticklabels=clf.classes_, yticklabels=clf.classes_, fmt='g')\n",
    "    plt.title(name)\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.show()\n",
    "    \n",
    "    return acc, err, pre, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(data, pre_processing_step):\n",
    "    print(pre_processing_step)\n",
    "    experiment_df = data\n",
    "    start_time = time.time()\n",
    "    experiment_df['text'] = experiment_df['text'].apply(pre_processing_step)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Creating a corpus (list of documents)\n",
    "    corpus = []\n",
    "    for idx, row in experiment_df.iterrows():\n",
    "        corpus.append(row['text'])\n",
    "    \n",
    "    # Using tf-idf representation as a baseline featutre representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    #vectorizer = TfidfVectorizer(max_features=400)\n",
    "    \n",
    "    X = vectorizer.fit_transform(corpus).toarray()\n",
    "    y = experiment_df['label']\n",
    "    \n",
    "    return X, y, start_time - end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, y, model_name, time):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)\n",
    "    \n",
    "    if model_name == 'NB':\n",
    "        model = MultinomialNB(fit_prior=False)\n",
    "    elif model_name == 'Deep':\n",
    "        model = keras.Sequential([\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),])\n",
    "        model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")   \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Running experiment\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_error = 1 - test_acc\n",
    "    print(test_acc, test_error)\n",
    "#     acc, err, pre, rec, f1 = report_metrics(y_test, predictions, model_name, model)\n",
    "    \n",
    "    return test_acc, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function apply_lem at 0x7fe393062320>\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2865\n",
      "0.2499626725912094 0.7500373274087906\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9752ffbfa1a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Deep\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     acc, err, pre, rec, f1, t = run_experiment(X, y, \"Deep\", t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Pre-Processing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Acuracy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Error'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precision'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1-Score'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre' is not defined"
     ]
    }
   ],
   "source": [
    "# Pre-processing options\n",
    "# apply_spelling_correction\n",
    "options = [apply_lem, apply_stemming, apply_contraction_expansion, apply_number_removal,\n",
    "          apply_punctuation_removal, apply_stopword_removal]\n",
    "options_string = ['lem', 'stemming', 'contraction_expansion', 'number_removal',\n",
    "          'punctuation_removal', 'stopword_removal']\n",
    "\n",
    "columns = ['Pre-Processing', 'Acuracy', 'Error', 'Precision', 'Recall', 'F1-Score', 'Time']\n",
    "\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for option, name in zip(options, options_string):\n",
    "    X, y, t = setup_experiment(movie_df, option)\n",
    "    acc, err = run_experiment(X, y, \"Deep\", t)\n",
    "#     acc, err, pre, rec, f1, t = run_experiment(X, y, \"Deep\", t)\n",
    "    df_dict = {'Pre-Processing':name, 'Acuracy':acc, 'Error':err, 'Precision':pre, 'Recall':rec, 'F1-Score':f1, 'Time':t}\n",
    "    results_df = results_df.append(df_dict, ignore_index=True)\n",
    "    \n",
    "for option, name in zip(options, options_string):\n",
    "    X, y, t = setup_experiment(movie_df, option)\n",
    "    acc, err, pre, rec, f1, t = run_experiment(X, y, \"NB\", t)\n",
    "    df_dict = {'Pre-Processing':name, 'Acuracy':acc, 'Error':err, 'Precision':pre, 'Recall':rec, 'F1-Score':f1, 'Time':t}\n",
    "    results_df = results_df.append(df_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_all = False\n",
    "if execute_all:\n",
    "    experiment_df = yelp_df\n",
    "    experiment_df['text'] = experiment_df['text'].apply(apply_lem)\n",
    "    print(1)\n",
    "    experiment_df['text'] = experiment_df['text'].apply(apply_stemming)\n",
    "    print(2)\n",
    "    experiment_df['text'] = experiment_df['text'].apply(apply_contraction_expansion)\n",
    "    print(3)\n",
    "    experiment_df['text'] = experiment_df['text'].apply(apply_number_removal)\n",
    "    print(4)\n",
    "    experiment_df['text'] = experiment_df['text'].apply(apply_punctuation_removal)\n",
    "    print(5)\n",
    "    experiment_df['text'] = experiment_df['text'].apply(apply_stopword_removal)\n",
    "    print(6)\n",
    "\n",
    "    # Creating a corpus (list of documents)\n",
    "    corpus = []\n",
    "    for idx, row in experiment_df.iterrows():\n",
    "        corpus.append(row['text'])\n",
    "\n",
    "    # Using tf-idf representation as a baseline featutre representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    #vectorizer = TfidfVectorizer(max_features=400)\n",
    "\n",
    "    X = vectorizer.fit_transform(corpus).toarray()\n",
    "    y = experiment_df['stars']\n",
    "\n",
    "    run_experiment(X, y, \"NB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Models\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "\n",
    "# Deep Learning (idk steal one of the previous ones we made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Collection & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
